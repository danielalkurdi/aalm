{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5811e540",
   "metadata": {},
   "source": [
    "# AALM — Data Preparation with semchunk\n",
    "Build an Administrative Law–focused dataset from the Open Australian Legal Corpus using `semchunk`.\n",
    "\n",
    "This notebook filters the corpus for Administrative Law material by keywords (tribunals, judicial review concepts, FOI, etc.),\n",
    "chunks the texts with `semchunk`, and saves a `text`-only dataset for SFT/QLoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14e5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install -U datasets semchunk transformers tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6bf896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tokenizer: openai/gpt-oss-20b\n",
      "Chunk size: 1024 Overlap: 0.2\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, itertools\n",
    "from typing import Dict, Any, List\n",
    "from datasets import load_dataset, Dataset\n",
    "import semchunk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "CORPUS_DATASET = os.environ.get('CORPUS_DATASET', 'isaacus/open-australian-legal-corpus')\n",
    "CORPUS_SPLIT = os.environ.get('CORPUS_SPLIT', 'corpus')\n",
    "OUTPUT_DIR = os.environ.get('OUTPUT_DIR', 'data/aalm-adminlaw-semchunk')\n",
    "BASE_TOKENIZER = os.environ.get('BASE_TOKENIZER', 'openai/gpt-oss-20b')  # used for token counting\n",
    "CHUNK_SIZE = int(os.environ.get('CHUNK_SIZE', '1024'))\n",
    "OVERLAP = float(os.environ.get('OVERLAP', '0.2'))\n",
    "DOC_LIMIT = int(os.environ.get('DOC_LIMIT', '0'))  # 0 = no explicit cap; use for quick dry runs\n",
    "\n",
    "# Broad Administrative Law signal via keywords (case-insensitive)\n",
    "ADMIN_KEYWORDS = [\n",
    "    'administrative appeals tribunal', 'aat', 'administrative decisions tribunal',\n",
    "    'civil and administrative tribunal', 'ncat', 'vcat', 'qcat', 'acat',\n",
    "    'merits review', 'judicial review', 'procedural fairness', 'natural justice',\n",
    "    'jurisdictional error', 'wednesbury', 'unreasonableness',\n",
    "    'freedom of information', 'foi', 'ombudsman',\n",
    "    'delegate', 'delegated legislation', 'minister', 'review of decision',\n",
    "    'administrative arrangement', 'administrative review tribunal', 'visa'\n",
    "]\n",
    "KW = re.compile('|'.join(re.escape(k) for k in ADMIN_KEYWORDS), flags=re.I)\n",
    "\n",
    "def is_admin_law(record: Dict[str, Any]) -> bool:\n",
    "    citation = (record.get('citation') or '')\n",
    "    text = (record.get('text') or '')\n",
    "    return bool(KW.search(citation + '\\n' + text))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_TOKENIZER, use_fast=True)\n",
    "chunker = semchunk.chunkerify(tokenizer, chunk_size=min(CHUNK_SIZE, getattr(tokenizer, 'model_max_length', CHUNK_SIZE)))\n",
    "print('Using tokenizer:', BASE_TOKENIZER)\n",
    "print('Chunk size:', CHUNK_SIZE, 'Overlap:', OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0dd7a",
   "metadata": {},
   "source": [
    "## Load and filter the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21dba636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using streaming mode (no total count available)\n",
      "Reached sample limit of 1000 documents\n",
      "Processed 1001 documents\n",
      "Matched Administrative Law docs: 670\n"
     ]
    }
   ],
   "source": [
    "USE_STREAMING = bool(os.environ.get('USE_STREAMING', 'True').lower() in ['true', '1', 'yes'])\n",
    "SAMPLE_SIZE = int(os.environ.get('SAMPLE_SIZE', '1000'))  # 0 = process all\n",
    "\n",
    "if USE_STREAMING:\n",
    "    corpus = load_dataset(CORPUS_DATASET, split=CORPUS_SPLIT, streaming=True)\n",
    "    print('Using streaming mode (no total count available)')\n",
    "else:\n",
    "    corpus = load_dataset(CORPUS_DATASET, split=CORPUS_SPLIT, keep_in_memory=False)\n",
    "    print('Total documents in split:', len(corpus))\n",
    "\n",
    "admin_docs = []\n",
    "count = 0\n",
    "processed = 0\n",
    "for ex in corpus:\n",
    "    processed += 1\n",
    "    if SAMPLE_SIZE and processed > SAMPLE_SIZE:\n",
    "        print(f'Reached sample limit of {SAMPLE_SIZE} documents')\n",
    "        break\n",
    "    \n",
    "    if not ex.get('text'):\n",
    "        continue\n",
    "    if is_admin_law(ex):\n",
    "        admin_docs.append(ex)\n",
    "        count += 1\n",
    "        if DOC_LIMIT and count >= DOC_LIMIT:\n",
    "            break\n",
    "\n",
    "print(f'Processed {processed} documents')\n",
    "print('Matched Administrative Law docs:', len(admin_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877821e",
   "metadata": {},
   "source": [
    "## Chunk texts with semchunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530b8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 12643\n"
     ]
    }
   ],
   "source": [
    "texts: List[str] = []\n",
    "citations: List[str] = []\n",
    "jurisdictions: List[str] = []\n",
    "types: List[str] = []\n",
    "urls: List[str] = []\n",
    "\n",
    "for ex in admin_docs:\n",
    "    chunks = chunker(ex['text'], overlap=OVERLAP)\n",
    "    n = len(chunks)\n",
    "    texts.extend(chunks)\n",
    "    citations.extend([ex.get('citation') or ''] * n)\n",
    "    jurisdictions.extend([ex.get('jurisdiction') or ''] * n)\n",
    "    types.extend([ex.get('type') or ''] * n)\n",
    "    urls.extend([ex.get('url') or ''] * n)\n",
    "\n",
    "print('Total chunks:', len(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d3145",
   "metadata": {},
   "source": [
    "## Save dataset to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3d1838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac8c2e5f6f6416cb5bb38e53cbe6ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12643 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/aalm-adminlaw-semchunk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': [\"Proclamation under the Commonwealth Powers (De Facto Relationships) Act 2006\\n\\nI, the Governor in and over the State of Tasmania and its Dependencies in the Commonwealth of Australia, acting with the advice of the Executive Council, by this my proclamation made under section 2 of the Commonwealth Powers (De Facto Relationships) Act 2006 fix 8 October 2008 as the day on which that Act commences.\\n\\n29 September 2008\\n\\nPETER G. UNDERWOOD\\n\\nGovernor\\n\\nBy His Excellency's Command,\\n\\nLARA GIDDINGS\\n\\nMinister for Justice\\n\\nDisplayed and numbered in accordance with the Rules Publication Act 1953.\\n\\nNotified in the Gazette on 8 October 2008\\n\\nThis proclamation is administered in the Department of Justice.\",\n",
       "  \"Local Government Order 2004\\n\\nI make the following order under section 137(1)(b) of the Local Government Act 1993 .\\n\\n21 September 2004\\n\\nJ. G. COX\\n\\nMinister Assisting the Premier on Local Government\\n\\n1. Short title\\n    This order may be cited as the Local Government Order 2004 .\\n\\n2. Commencement\\n    This order takes effect on the day on which its making is notified in the Gazette.\\n\\n3. Transfer of land to Break O'Day Council\\n    The land situated at Gillies Road in St Marys in Tasmania comprised in Volume 206762, Folio 1 of the Register kept under section 33 of the Land Titles Act 1980 is to be transferred to the Break O'Day Council.\\n\\nDisplayed and numbered in accordance with the Rules Publication Act 1953.\\n\\nNotified in the Gazette on 6 October 2004\\n\\nThis order is administered in the Department of Premier and Cabinet.\"],\n",
       " 'citation': ['Proclamation under the Commonwealth Powers (De Facto Relationships) Act 2006 (Tas)',\n",
       "  'Local Government Order 2004 (Tas)'],\n",
       " 'jurisdiction': ['tasmania', 'tasmania'],\n",
       " 'type': ['secondary_legislation', 'secondary_legislation'],\n",
       " 'url': ['https://www.legislation.tas.gov.au/view/whole/html/inforce/current/sr-2008-119',\n",
       "  'https://www.legislation.tas.gov.au/view/whole/html/inforce/current/sr-2004-080']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = Dataset.from_dict({\n",
    "    'text': texts,\n",
    "    'citation': citations,\n",
    "    'jurisdiction': jurisdictions,\n",
    "    'type': types,\n",
    "    'url': urls,\n",
    "})\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "out.save_to_disk(OUTPUT_DIR)\n",
    "print('Saved to', OUTPUT_DIR)\n",
    "out[:2]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
